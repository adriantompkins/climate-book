{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a925c76-2c9c-4841-8de2-1318c6d6cd1a",
   "metadata": {},
   "source": [
    "# Rainfall indices based on the Indian monsoon\n",
    "\n",
    "in this lesson we are going to apply some of the basics we have learned from the video course concerning the simple manipulation of netcdf files using cdo.  The examples are based on the analysis of the GPCP data.  To help you get the data fast to your machine I've placed a copy of an older version on my dods server, since accessing the latest version from NASA requires a time consuming registration process.  To see how to do this, [read this NASA page](). You can then replace this version of gpcp later if you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f51797b-3e45-4c49-9d45-dc058a0d4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to install:\n",
    "# MAC brew install (or port install)\n",
    "# UBUNTU sudo apt install\n",
    "#\n",
    "# cdo\n",
    "# wget\n",
    "# ncview\n",
    "# netcdf-dev (ubuntu) netcdf (brew)\n",
    "\n",
    "year1=1998\n",
    "year2=2005\n",
    "ddir=\"../../DATA/gpcp\"\n",
    "fname=gpcp_v01r03_daily_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03108f-e507-4956-9268-ad5d42956e31",
   "metadata": {},
   "source": [
    "here we pull the data from the ICTP server using wget...  But you can also follow my video course and write an API to get rainfall data from ERA5 or an alternative retrieval from the CDS if you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d11e2-a788-4c79-bc64-5b5e2a532aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 12:56:24--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_1998.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94726499 (90M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_1998.nc.1’\n",
      "\n",
      "gpcp_v01r03_daily_1 100%[===================>]  90.34M  4.02MB/s    in 23s     \n",
      "\n",
      "2025-03-06 12:56:47 (3.90 MB/s) - ‘./gpcp/gpcp_v01r03_daily_1998.nc.1’ saved [94726499/94726499]\n",
      "\n",
      "--2025-03-06 12:56:47--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_1999.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94726499 (90M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_1999.nc’\n",
      "\n",
      "gpcp_v01r03_daily_1 100%[===================>]  90.34M  4.32MB/s    in 22s     \n",
      "\n",
      "2025-03-06 12:57:09 (4.19 MB/s) - ‘./gpcp/gpcp_v01r03_daily_1999.nc’ saved [94726499/94726499]\n",
      "\n",
      "--2025-03-06 12:57:09--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_2000.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94985781 (91M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_2000.nc’\n",
      "\n",
      "gpcp_v01r03_daily_2 100%[===================>]  90.58M  4.12MB/s    in 24s     \n",
      "\n",
      "2025-03-06 12:57:33 (3.84 MB/s) - ‘./gpcp/gpcp_v01r03_daily_2000.nc’ saved [94985781/94985781]\n",
      "\n",
      "--2025-03-06 12:57:33--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_2001.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94726499 (90M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_2001.nc’\n",
      "\n",
      "gpcp_v01r03_daily_2 100%[===================>]  90.34M  3.51MB/s    in 24s     \n",
      "\n",
      "2025-03-06 12:57:57 (3.76 MB/s) - ‘./gpcp/gpcp_v01r03_daily_2001.nc’ saved [94726499/94726499]\n",
      "\n",
      "--2025-03-06 12:57:57--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_2002.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94726499 (90M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_2002.nc’\n",
      "\n",
      "gpcp_v01r03_daily_2 100%[===================>]  90.34M  4.30MB/s    in 22s     \n",
      "\n",
      "2025-03-06 12:58:18 (4.15 MB/s) - ‘./gpcp/gpcp_v01r03_daily_2002.nc’ saved [94726499/94726499]\n",
      "\n",
      "--2025-03-06 12:58:19--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_2003.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94726499 (90M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_2003.nc’\n",
      "\n",
      "gpcp_v01r03_daily_2 100%[===================>]  90.34M  4.73MB/s    in 22s     \n",
      "\n",
      "2025-03-06 12:58:40 (4.17 MB/s) - ‘./gpcp/gpcp_v01r03_daily_2003.nc’ saved [94726499/94726499]\n",
      "\n",
      "--2025-03-06 12:58:40--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_2004.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94985781 (91M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_2004.nc’\n",
      "\n",
      "gpcp_v01r03_daily_2 100%[===================>]  90.58M  4.75MB/s    in 18s     \n",
      "\n",
      "2025-03-06 12:58:58 (5.16 MB/s) - ‘./gpcp/gpcp_v01r03_daily_2004.nc’ saved [94985781/94985781]\n",
      "\n",
      "--2025-03-06 12:58:58--  http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/gpcp_v01r03_daily_2005.nc\n",
      "Resolving clima-dods.ictp.it (clima-dods.ictp.it)... 140.105.16.180\n",
      "Connecting to clima-dods.ictp.it (clima-dods.ictp.it)|140.105.16.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94726499 (90M) [application/x-netcdf]\n",
      "Saving to: ‘./gpcp/gpcp_v01r03_daily_2005.nc’\n",
      "\n",
      "gpcp_v01r03_daily_2 100%[===================>]  90.34M  4.87MB/s    in 18s     \n",
      "\n",
      "2025-03-06 12:59:16 (5.09 MB/s) - ‘./gpcp/gpcp_v01r03_daily_2005.nc’ saved [94726499/94726499]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "\n",
    "\n",
    "mkdir -p ./gpcp\n",
    "stub=gpcp_v01r03_daily_\n",
    "for year in $(seq ${year1} ${year2}); do\n",
    "   wget -P $ddir http://clima-dods.ictp.it/Users/tompkins/Observations/GPCP/v1.3/${stub}${year}.nc\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39aa159-7a89-4a24-9faf-7bac78fe13b1",
   "metadata": {},
   "source": [
    "# Cutting out areas\n",
    "\n",
    "first of all we need to cut out an area, what is the CDO command that is used for this ?\n",
    "\n",
    "<details>\n",
    "<summary>Click here for answer</summary>\n",
    "The command we use is \"sellonlatbox\"\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b0ac0d0-2906-4e95-927c-06bf03cb5db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.08s 43MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 42MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23716800 values from 1 variable over 366 timesteps [0.07s 42MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.06s 41MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.06s 42MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 43MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23716800 values from 1 variable over 366 timesteps [0.07s 42MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.06s 41MB]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's first cut out an area \n",
    "#\n",
    "# lon1, lon2, lat1, lat2\n",
    "india=\"65,90,8,27\"\n",
    "wafrica=\"-20,20,-5,30\"\n",
    "\n",
    "region=$india\n",
    "region_tag=_area$(echo $region | tr , _) \n",
    "\n",
    "for year in $(seq ${year1} ${year2}); do\n",
    "    ifile=${ddir}/${fname}${year}.nc\n",
    "    ofile=${ddir}/${fname}${year}${region_tag}.nc\n",
    "    cdo sellonlatbox,${region} $ifile $ofile\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061a3fb5-a44a-44c5-a8fd-04317e302a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.08s 43MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 43MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23716800 values from 1 variable over 366 timesteps [0.07s 41MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 43MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 42MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 44MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23716800 values from 1 variable over 366 timesteps [0.07s 43MB]\n",
      "\u001b[32mcdo    sellonlatbox: \u001b[0mProcessed 23652000 values from 1 variable over 365 timesteps [0.07s 43MB]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lon1=65\n",
    "lon2=90\n",
    "lat1=8\n",
    "lat2=27\n",
    "\n",
    "region=\"${lon1},${lon2},${lat1},${lat2}\"\n",
    "region_tag=area_${lon1}_${lon2}_${lat1}_${lat2}\n",
    "\n",
    "for year in $(seq ${year1} ${year2}); do\n",
    "    ifile=${ddir}/${fname}${year}.nc\n",
    "    ofile=${ddir}/${fname}${year}_${region_tag}.nc\n",
    "    cdo sellonlatbox,${region} $ifile $ofile\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99581e67-d4ac-4201-a936-b5fc7da666a0",
   "metadata": {},
   "source": [
    "# Merging files\n",
    "\n",
    "now we want to merge the files into a single file for the whole period and just select the summer months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "157f01cd-da37-45b7-82e0-99d24fbfdcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    mergetime: \u001b[0mProcessed 1519440 values from 8 variables over 2922 timesteps [0.32s 58MB]\n",
      "\u001b[32mcdo    selmonth: \u001b[0mProcessed 507520 values from 1 variable over 2922 timesteps [0.17s 48MB]\n"
     ]
    }
   ],
   "source": [
    "# now the files are much smaller, let's put them together in a single file for ease\n",
    "cdo -O mergetime ${ddir}/${fname}????${region_tag}.nc ${ddir}/${fname}${region_tag}.nc\n",
    "\n",
    "# just select the summer months\n",
    "cdo -O selmon,6/9 ${ddir}/${fname}${region_tag}.nc ${ddir}/${fname}${region_tag}_JJAS.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4c1cb-f837-49cd-b98b-896bfa042942",
   "metadata": {},
   "source": [
    "# Examine the files\n",
    "\n",
    "Let's take a look at the resulting file with ncview\n",
    "\n",
    "Once you are familiar with the details, let's start to make some more involved indices \n",
    "\n",
    "These follow https://arxiv.org/abs/2404.12419\n",
    "\n",
    "We first calculate the anomaly of the annual rainy season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e368beb5-d1cd-480e-9b67-f1062b6de351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo(1) timmean: \u001b[0mProcess started\n",
      "\u001b[32mcdo    sub: \u001b[0mFilling up stream2 >(pipe1.4)< by copying the first timestep.\n",
      "\u001b[32mcdo    sub: \u001b[0mProcessed 508040 values from 2 variables over 977 timesteps [0.18s 47MB]\n",
      "\u001b[32mcdo    yearmean: \u001b[0mProcessed 507520 values from 1 variable over 976 timesteps [0.07s 39MB]\n"
     ]
    }
   ],
   "source": [
    "# now we have a single file, let's look at the annual anomaly\n",
    "cdo timmean ${ddir}/${fname}${region_tag}_JJAS.nc ${ddir}/${fname}${region_tag}_JJAS_timmean.nc\n",
    "cdo sub ${ddir}/${fname}${region_tag}_JJAS.nc ${ddir}/${fname}${region_tag}_JJAS_timmean.nc ${ddir}/${fname}${region_tag}_JJAS_anom.nc\n",
    "cdo yearmean ${ddir}/${fname}${region_tag}_JJAS_anom.nc ${ddir}/${fname}${region_tag}_JJAS_anom_yearmean.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb3275-0d01-47b9-8d65-4bb94ccaf8a4",
   "metadata": {},
   "source": [
    "# Spatial averaging\n",
    "\n",
    "The spatial average is actually not straightforward to calculate offline.  As is clear from the video, one needs to account for the grid cell size, which means with a regular lat-long grid, weighting for the cosine of the latitude. Luckily cdo accounts for different grid mesh sizes in its fldmean function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93de086-52a7-4509-b953-bde7df7217a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    fldmean: \u001b[0mProcessed 4160 values from 1 variable over 8 timesteps [0.02s 33MB]\n"
     ]
    }
   ],
   "source": [
    "# let's make an all-region index\n",
    "cdo fldmean ${ddir}/${fname}${region_tag}_JJAS_anom_yearmean.nc ${ddir}/${fname}${region_tag}_JJAS_anom_meanindex.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d77663-3271-4dc5-b179-7ccd48474f13",
   "metadata": {},
   "source": [
    "# Now we can start to use CDO to calculate more interesting indices\n",
    "\n",
    "### TASK 1:  A wet area index.  \n",
    "\n",
    "Take a moment to think about this before reading on. You need to use cdo to make the \"wet-area\" index, which is  the fraction of a region that has had a <b>positive</b> rainfall anomaly in a given particular year... \n",
    "\n",
    "In order to do this you will need to use a logical function, like \n",
    "\n",
    "- ```ge``` (greater than or equal) which compares two fields and produces a 1 if the first field is larger than or equal to the second, 0 otherwise, or\n",
    "- ```gtc``` (greater than a constant), which requires an argument (e.g. ```gec,5``` no spaces!) which then gives a 1 if the input field is greater than the threshold.\n",
    "\n",
    "<details>\n",
    "<summary>Which of these two function do we need to use here?</summary>\n",
    "Either can work!  We will need *gec* if we are to see if the anomaly is above zero.  But you don't need to calculate the anomaly necessarily, you could also use ```cdo ge``` to compare the annual mean precipitation directly to the climatology!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589c1370-fb8b-4b1d-b8ee-dc16d01c5098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    gec: \u001b[0mProcessed 4160 values from 1 variable over 8 timesteps [0.02s 33MB]\n",
      "\u001b[32mcdo    fldmean: \u001b[0mProcessed 4160 values from 1 variable over 8 timesteps [0.02s 33MB]\n"
     ]
    }
   ],
   "source": [
    "# now we can start to look at the wet area index\n",
    "# first we set to 1 all points that are with a positive anomaly\n",
    "cdo gec,0 ${ddir}/${fname}${region_tag}_JJAS_anom_yearmean.nc ${ddir}/${fname}${region_tag}_JJAS_anom_binary.nc\n",
    "\n",
    "# and now we can add up all the 1s to see what the wet area is\n",
    "cdo fldmean ${ddir}/${fname}${region_tag}_JJAS_anom_binary.nc ${ddir}/${fname}${region_tag}_JJAS_wetarea_index.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71a8e9-69d4-4052-922c-74d4206e6efe",
   "metadata": {},
   "source": [
    "### TASK 2: Number of extreme rainy days\n",
    "\n",
    "In this task you will need to calculate first the 95th percentile of rainfall, and then sum up the number of days within the monsoon season each year that exceed this threshold for each location..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5763936-0142-4654-97f1-6cf31b6ebea5",
   "metadata": {},
   "source": [
    "## Percentiles.\n",
    "\n",
    "Let's say you have a collection of $n$ observations $o_i$.  The Xth percentile simply gives the threshold below which $X$ % of the distribution lies.  Now if $n$ is large, you could simply line up the number in ascending order and make the cut at the point where $X$% of the numbers are smaller than your chosen threshold.  However usually your sample is not large enough, in which case it is common to assume that the sampled values fit a common distribution (e.g. one might assume that they are Normally distributed).  The distribution can be fitted by various methods such as moment matching, and then the thresholds are derived from the fitted distribution.\n",
    "\n",
    "CDO has a number of built-in options that are derived from the relevant python package scipy:\n",
    "\n",
    "- nrank\n",
    "- nist\n",
    "- rtype8\n",
    "- linear\n",
    "- lower\n",
    "- higher\n",
    "- nearest\n",
    "- midpoint\n",
    "- inverted_cdf\n",
    "- averaged_inverted_cdf\n",
    "- closest_observation\n",
    "- interpolated_inverted_cdf\n",
    "- hazen\n",
    "- weibull\n",
    "- median_unbiased\n",
    "- normal_unbiased\n",
    "\n",
    "As you can see the list is long!  We will therefore not delve into the details here, but refer you to the [cdo percentile documentation](https://code.mpimet.mpg.de/projects/cdo/embedded/index.html#x1-520001.10) for this method.  For large samples, there is very little difference between the methods. We simply use the default method in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fdc13c0-e865-4cd0-add9-77d08a25fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo(1) timmin: \u001b[0mProcess started\n",
      "\u001b[32mcdo(2) timmax: \u001b[0mProcess started\n",
      "\u001b[32mcdo    timpctl: \u001b[0mProcessed 508560 values from 3 variables over 978 timesteps [0.20s 50MB]\n",
      "\u001b[32mcdo    ge: \u001b[0mFilling up stream2 >../../DATA/gpcp/gpcp_v01r03_daily__area65_90_8_27_JJAS_p95.nc< by copying the first timestep.\n",
      "\u001b[32mcdo    ge: \u001b[0mProcessed 508040 values from 2 variables over 977 timesteps [0.11s 44MB]\n",
      "\u001b[32mcdo    yearsum: \u001b[0mProcessed 507520 values from 1 variable over 976 timesteps [0.07s 38MB]\n"
     ]
    }
   ],
   "source": [
    "# make a index for extremes P95 for example\n",
    "ifile=${ddir}/${fname}${region_tag}_JJAS.nc\n",
    "percen=95\n",
    "cdo timpctl,${percen} $ifile -timmin $ifile -timmax $ifile ${ddir}/${fname}${region_tag}_JJAS_p${percen}.nc\n",
    "\n",
    "cdo ge $ifile ${ddir}/${fname}${region_tag}_JJAS_p${percen}.nc ${ddir}/${fname}${region_tag}_JJAS_p${percen}_binary.nc\n",
    "\n",
    "# number of extreme rainy days per year\n",
    "cdo yearsum ${ddir}/${fname}${region_tag}_JJAS_p${percen}_binary.nc ${ddir}/${fname}${region_tag}_JJAS_p${percen}_nevents.nc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e26fd-3aab-422e-b334-48e61c502f98",
   "metadata": {},
   "source": [
    "### TASK 3 : Hands on/Homework\n",
    "\n",
    "Repeat the above exercises for another region that interests you, (e.g. West African monsoon, south American monsoon, Europe, take an area that interests you). Remember that if you cut down the seasons within the year to target the months when the rains arrive if you are focussing on a monsoon region!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b57795-90a2-4857-a22d-9f3790c4b87f",
   "metadata": {},
   "source": [
    "### TASK 4 : Homework\n",
    "\n",
    "Download from the dataserver SST data for the Pacific region, read up on the ENSO 3.4 index and think about how you could use CDO to make a simple ENSO index. This will be the topic of the next lecture, so don't worry if you get stuck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e80195-b8e9-47cf-ba99-b55645d56cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
